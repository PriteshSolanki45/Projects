import os
from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_groq import ChatGroq

app = Flask(__name__)
CORS(app)
load_dotenv()

UPLOAD_FOLDER = "uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

conversation = None

# --- Helpers ---
def allowed_file(filename):
    return filename.lower().endswith(".pdf")

def extract_text(pdf_paths):
    text = ""
    for path in pdf_paths:
        reader = PdfReader(path)
        for page in reader.pages:
            text += page.extract_text() or ""
    return text

def make_chunks(text):
    splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    return splitter.split_text(text)

def make_vectorstore(chunks):
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"}
    )
    return FAISS.from_texts(chunks, embedding=embeddings)

def make_conversation_chain(vs):
    llm = ChatGroq(
        model="llama-3.3-70b-versatile",
        temperature=0.5,
        api_key=os.getenv("GROQ_API_KEY")
    )
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vs.as_retriever(),
        memory=memory
    )

# --- Routes ---
@app.route("/upload", methods=["POST"])
def upload():
    global conversation
    files = request.files.getlist("files")
    pdf_paths = []
    for f in files:
        if allowed_file(f.filename):
            path = os.path.join(UPLOAD_FOLDER, secure_filename(f.filename))
            f.save(path)
            pdf_paths.append(path)

    if not pdf_paths:
        return jsonify({"error": "No valid PDFs uploaded"}), 400

    text = extract_text(pdf_paths)
    chunks = make_chunks(text)
    vs = make_vectorstore(chunks)
    conversation = make_conversation_chain(vs)

    return jsonify({"message": "PDFs processed successfully"})

@app.route("/ask", methods=["POST"])
def ask():
    global conversation
    if not conversation:
        return jsonify({"error": "No PDFs processed yet"}), 400

    question = request.json.get("question")
    if not question:
        return jsonify({"error": "No question provided"}), 400

    result = conversation({"question": question})
    return jsonify({
        "answer": result["answer"],
        "history": [(m.type, m.content) for m in result["chat_history"]]
    })

@app.route("/health")
def health():
    return jsonify({"status": "ok"})

if __name__ == "__main__":
    app.run(port=5000, debug=True)
